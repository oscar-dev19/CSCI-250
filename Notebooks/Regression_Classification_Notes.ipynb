{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression and Classification\n",
    "\n",
    "---\n",
    "\n",
    "## Classification\n",
    "\n",
    "Classification algorithms attempt to estimate mapping functions(f) from the input variables(x) to discrete categorical output variables (y).\n",
    "\n",
    "Y variable is the category the mapping funciton predicts. A classification model will attempt to predict the value of single or several conclusions.\n",
    "\n",
    "Appx. 70% of problems in data science are classification problems.\n",
    "\n",
    "Two types:\n",
    "    \n",
    "1: Binary\n",
    "2: Multinomial\n",
    "    \n",
    "Common classification algorithms:\n",
    "\n",
    "* Decision Trees\n",
    "* Logistic Regression\n",
    "* Naive Bayes\n",
    "* K-nearest neighbors.\n",
    "    \n",
    "Classification Workflow\n",
    "\n",
    "data --> Training set --> Model development\n",
    "\n",
    "                                            --> Model Evaluation --> Performance Measures (1:Accuracy, 2:Precision,\n",
    "                                            \n",
    "                                                                                           3:Recall)\n",
    "                                                                                           \n",
    "     --> Test Set     -->  \n",
    "     \n",
    "### Decision Trees\n",
    "\n",
    "A popular classification algorithm.\n",
    "\n",
    "Tree-like strucutred flow chart. Each node = test on an attribute. Each branch represents an outcome of the test. Each leaf node (terminal node) = class label.\n",
    "\n",
    "Code: DecisionTreeExample.ipynb\n",
    "\n",
    "\n",
    "# Activation Funcions\n",
    "\n",
    "---\n",
    "\n",
    "* Sigmoid function\n",
    "    \n",
    "    - Takes any range real number and returns a value between 0 and 1.\n",
    "    \n",
    "    - The output value is expected to be in the range of -1 and 1. Produces an S shape curve.\n",
    "\n",
    "    f(x) = (1/1+exp^-x)\n",
    "    \n",
    "    - The first derivative of the sigmoid functikn will be non-negative or non-positive.\n",
    "\n",
    "* ReLu Activation Function\n",
    "\n",
    "    - Rectified Linear Unit function = most widely used deep learning with state-of-the-art results.\n",
    "    \n",
    "    - usually achieves better results and performance.\n",
    "    \n",
    "    f(x) = max(0,x)\n",
    "    \n",
    "* Softmax Activation function\n",
    "\n",
    "    - Used for prediction of multi-class models.\n",
    "    \n",
    "    - Returns probabilities of each class in a group of different classes with the highest target class having the highest probability.\n",
    "    \n",
    "    f(x) = exp(x)/sum(exp(x))\n",
    "    \n",
    "    - Produces output in range 0 and 1 with the sum of all probabilities = 1.\n",
    "    \n",
    "    - Difference between sigmoid: Sigmoid used in binary classification and softmax used in multiclass tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
